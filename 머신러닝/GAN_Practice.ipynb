{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiP9H1n6u1N4"
   },
   "source": [
    "## 모델 동작에 필요한 사전 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ndYVmYg4u1N5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.9.2-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /home/piai/anaconda3/envs/ml/lib/python3.9/site-packages (from tensorflow_datasets) (1.4.0)\n",
      "Collecting array-record (from tensorflow_datasets)\n",
      "  Downloading array_record-0.2.0-py39-none-any.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /home/piai/anaconda3/envs/ml/lib/python3.9/site-packages (from tensorflow_datasets) (8.0.4)\n",
      "Collecting dm-tree (from tensorflow_datasets)\n",
      "  Downloading dm_tree-0.1.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (153 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting etils[enp,epath]>=0.9.0 (from tensorflow_datasets)\n",
      "  Downloading etils-1.3.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.4/126.4 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/piai/anaconda3/envs/ml/lib/python3.9/site-packages (from tensorflow_datasets) (1.23.5)\n",
      "Collecting promise (from tensorflow_datasets)\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.20 in /home/piai/anaconda3/envs/ml/lib/python3.9/site-packages (from tensorflow_datasets) (4.23.3)\n",
      "Requirement already satisfied: psutil in /home/piai/anaconda3/envs/ml/lib/python3.9/site-packages (from tensorflow_datasets) (5.9.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/piai/anaconda3/envs/ml/lib/python3.9/site-packages (from tensorflow_datasets) (2.28.1)\n",
      "Collecting tensorflow-metadata (from tensorflow_datasets)\n",
      "  Downloading tensorflow_metadata-1.13.1-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: termcolor in /home/piai/anaconda3/envs/ml/lib/python3.9/site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Requirement already satisfied: toml in /home/piai/anaconda3/envs/ml/lib/python3.9/site-packages (from tensorflow_datasets) (0.10.2)\n",
      "Collecting tqdm (from tensorflow_datasets)\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: wrapt in /home/piai/anaconda3/envs/ml/lib/python3.9/site-packages (from tensorflow_datasets) (1.12.1)\n",
      "Requirement already satisfied: importlib_resources in /home/piai/anaconda3/envs/ml/lib/python3.9/site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (5.12.0)\n",
      "Requirement already satisfied: typing_extensions in /home/piai/anaconda3/envs/ml/lib/python3.9/site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (3.7.4.3)\n",
      "Requirement already satisfied: zipp in /home/piai/anaconda3/envs/ml/lib/python3.9/site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/piai/anaconda3/envs/ml/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/piai/anaconda3/envs/ml/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/piai/anaconda3/envs/ml/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/piai/anaconda3/envs/ml/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (2023.5.7)\n",
      "Requirement already satisfied: six in /home/piai/anaconda3/envs/ml/lib/python3.9/site-packages (from promise->tensorflow_datasets) (1.15.0)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0 (from tensorflow-metadata->tensorflow_datasets)\n",
      "  Downloading googleapis_common_protos-1.59.1-py2.py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21486 sha256=8873a4c1a391ef16f5248e366f97863e2fdb03f46c95ca938b0968879ce577c9\n",
      "  Stored in directory: /home/piai/.cache/pip/wheels/e1/e8/83/ddea66100678d139b14bc87692ece57c6a2a937956d2532608\n",
      "Successfully built promise\n",
      "Installing collected packages: dm-tree, tqdm, promise, googleapis-common-protos, etils, tensorflow-metadata, array-record, tensorflow_datasets\n",
      "Successfully installed array-record-0.2.0 dm-tree-0.1.8 etils-1.3.0 googleapis-common-protos-1.59.1 promise-2.3 tensorflow-metadata-1.13.1 tensorflow_datasets-4.9.2 tqdm-4.65.0\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oIDmcz3Lu1N6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 09:29:30.101805: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-21 09:29:30.127863: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-21 09:29:30.300492: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-21 09:29:30.302077: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-21 09:29:31.192765: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras import Model, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KmCCRSm5u1N6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 09:29:33.154758: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9WJjBB5u1N6"
   },
   "source": [
    "## 데이터 불러오기 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vCssQhy5u1N6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 09:29:36.864013: W tensorflow/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /home/piai/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd419d0d22d400289b5c74a9c97616c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to /home/piai/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 이번 GAN 실습에 활용될 MNIST 데이터를 다운로드한 후,\n",
    "# 불러온 데이터를 Training용과 Testing용으로 나누는 과정\n",
    "# 모든 이미지 데이터의 크기는 28 x 28 x 1 (흑백)\n",
    "\n",
    "dataset = tfds.load('mnist', split = 'train')\n",
    "batch_size = 1024\n",
    "train_data = dataset.map(lambda data: tf.cast(data['image'], tf.float32) / 255.).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkhK8fQHu1N7"
   },
   "source": [
    "## GAN 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjKc59Blu1N7"
   },
   "source": [
    "### GAN의 생성자 (Generator) 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4rGB0yo3u1N7"
   },
   "outputs": [],
   "source": [
    "# GAN의 생성자 (Generator)\n",
    "\n",
    "class Generator(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        # 2D convolutional layer의 역연산에 해당하는 transposed 2D convolutional layer의 경우,\n",
    "        # same padding을 적용하고 strides 값을 2로 할 경우 이미지의 크기가 두 배로 확장되는 효과!\n",
    "        self.latent_dim = latent_dim\n",
    "        self.generator = tf.keras.Sequential([\n",
    "\n",
    "            layers.Dense(7 * 7 * 32, activation = 'relu'),                                          # (batch_size, 7 * 7 * 32) , input_shape = (latent_dim, )\n",
    "            layers.Reshape((7, 7, 32)),                                                             # (batch_size, 7, 7, 32)\n",
    "            layers.Conv2DTranspose(64, 3, strides = 2, padding = 'same', activation = 'relu'),      # (batch_size, 14, 14, 64)\n",
    "            layers.Conv2DTranspose(32, 3, strides = 2, padding = 'same', activation = 'relu'),      # (batch_size, 28, 28, 32)\n",
    "            layers.Conv2DTranspose(1, 3, strides = 1, padding = 'same', activation = 'sigmoid')     # (batch_size, 28, 28, 1)\n",
    "        ])\n",
    "\n",
    "    def call(self, z):\n",
    "        return self.generator(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGys1bBDu1N7"
   },
   "source": [
    "### GAN의 판별자 (Discriminator) 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VN7pQ9syu1N7"
   },
   "outputs": [],
   "source": [
    "# GAN의 판별자 (Discriminator)\n",
    "\n",
    "class Discriminator(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        # 2D convolutional layer에서 same padding을 적용하고 strides 값을 2로 할 경우 이미지의 크기가 절반으로 줄어드는 효과!\n",
    "        self.latent_dim = latent_dim\n",
    "        self.discriminator = tf.keras.Sequential([\n",
    "            layers.Conv2D(32, 3, strides = 2, activation = 'relu', padding = 'same', input_shape = (28, 28, 1)),    # (batch_size, 14, 14, 32)\n",
    "            layers.Conv2D(64, 3, strides = 2, activation = 'relu', padding = 'same'),                               # (batch_size, 7, 7, 64)\n",
    "            layers.Flatten(),                                                                                       # (batch_size, 7 * 7 * 64)\n",
    "            layers.Dense(1)                                                                                         # (batch_size, )\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.discriminator(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Re-ByBhu1N8"
   },
   "source": [
    "### GAN 구조 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SrJmxq8gu1N8"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "n_epochs = 200\n",
    "latent_dim = 10\n",
    "log_interval = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DJVVSyI8u1N8"
   },
   "outputs": [],
   "source": [
    "# GAN의 생성자와 판별자\n",
    "\n",
    "generator = Generator(latent_dim)\n",
    "discriminator = Discriminator(latent_dim)\n",
    "\n",
    "\n",
    "# Optimizer 정의\n",
    "optimizer_g = tf.keras.optimizers.Adam(1e-3)\n",
    "optimizer_d = tf.keras.optimizers.Adam(1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqDDhZgUu1N8"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sZpMoI0u1N8"
   },
   "source": [
    "### Loss Function 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fws7jxFJu1N8"
   },
   "outputs": [],
   "source": [
    "# Loss function은 binary cross entropy (BCE)로 정의\n",
    "\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "22yHGxe9u1N8"
   },
   "outputs": [],
   "source": [
    "def train_step(inputs):\n",
    "    noises = tf.random.normal([batch_size, latent_dim])\n",
    "\n",
    "    with tf.GradientTape() as tape_g, tf.GradientTape() as tape_d:\n",
    "        # noises: random noise 분포에서 sample된 벡터\n",
    "        # x: noises로부터 생성된 MNIST 이미지\n",
    "        # real_output: 실제 MNIST 이미지 판별 결과\n",
    "        # fake_output: GAN의 생성자가 생성한 MNIST 이미지의 판별 결과\n",
    "\n",
    "        x = generator(noises) # 가짜이미지 / inputs -> 진짜 이미지\n",
    "        \n",
    "        real_output = discriminator(inputs) # discriminator -> 진짜라고 맞혀야 함 (1)\n",
    "        fake_output = discriminator(x) \n",
    "        # 1. discriminator -> fake output 0이라고 예측해야 함\n",
    "        # 2. generator -> discriminator 속여야 함 -> 1이 나오길 원해야 함\n",
    "\n",
    "        # Generator loss와 discriminator loss 계산\n",
    "        loss_g = loss(tf.ones_like(fake_output), fake_output)\n",
    "        loss_d = loss(tf.ones_like(real_output), real_output) + loss(tf.zeros_like(fake_output), fake_output)\n",
    "\n",
    "    # GAN을 구성하는 생성자와 판별자의 gradient 값들을 계산하는 과정\n",
    "    grads_g = tape_g.gradient(loss_g, generator.trainable_variables)\n",
    "    grads_d = tape_d.gradient(loss_d, discriminator.trainable_variables)\n",
    "\n",
    "    # 계산된 gradient 값들을 기반으로 GAN의 생성자와 판별자를 optimize하는 과정\n",
    "    optimizer_g.apply_gradients(zip(grads_g, generator.trainable_variables))\n",
    "    optimizer_d.apply_gradients(zip(grads_d, discriminator.trainable_variables))\n",
    "\n",
    "    return loss_g, loss_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zWUK4NNYu1N9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  20 - Generator loss: 171.91, Discriminator loss: 26.64\n",
      "Epoch  40 - Generator loss: 112.81, Discriminator loss: 43.61\n",
      "Epoch  60 - Generator loss: 79.91, Discriminator loss: 58.08\n",
      "Epoch  80 - Generator loss: 87.58, Discriminator loss: 57.62\n",
      "Epoch 100 - Generator loss: 86.98, Discriminator loss: 53.88\n",
      "Epoch 120 - Generator loss: 93.56, Discriminator loss: 51.23\n",
      "Epoch 140 - Generator loss: 85.82, Discriminator loss: 53.16\n",
      "Epoch 160 - Generator loss: 84.23, Discriminator loss: 55.20\n",
      "Epoch 180 - Generator loss: 83.84, Discriminator loss: 57.45\n",
      "Epoch 200 - Generator loss: 78.26, Discriminator loss: 59.47\n"
     ]
    }
   ],
   "source": [
    "# 실제 Training 과정\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    total_loss_g, total_loss_d = 0, 0\n",
    "\n",
    "    for x in train_data:\n",
    "        loss_g, loss_d = train_step(x)\n",
    "        total_loss_g += loss_g\n",
    "        total_loss_d += loss_d\n",
    "\n",
    "    if epoch % log_interval == 0:\n",
    "        print(f'Epoch {epoch:3d} - Generator loss: {total_loss_g:.2f}, Discriminator loss: {total_loss_d:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuJ95nmwu1N9"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOKJ6ypHu1N9"
   },
   "source": [
    "### 생성자 동작 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJRp6N3hu1N9"
   },
   "outputs": [],
   "source": [
    "# 학습된 GAN 모델의 생성자로 MNIST 이미지 Sampling 및 시각화\n",
    "\n",
    "noise = tf.random.normal([1, latent_dim])\n",
    "x = generator(noise)\n",
    "plt.imshow(x[0, :, :, 0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNEhLiivu1N9"
   },
   "source": [
    "### 학습된 GAN 모델로 MNIST 이미지 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_8TKJmC0u1N9"
   },
   "outputs": [],
   "source": [
    "# 여러 개의 MNIST 이미지들을 Sampling하는 함수 정의\n",
    "# n * n 정사각형 배치의 MNIST 이미지 생성 및 출력\n",
    "\n",
    "def plot_latent_images(n, digit_size = 28):\n",
    "    image_width = digit_size * n\n",
    "    image_height = image_width\n",
    "    image = np.zeros((image_height, image_width))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            noise = tf.random.normal([1, latent_dim])\n",
    "            x = generator(noise)\n",
    "            image[i * digit_size : (i + 1) * digit_size, j * digit_size : (j + 1) * digit_size] = x[0, :, :, 0]\n",
    "\n",
    "    plt.figure(figsize = (10, 10))\n",
    "    plt.imshow(image, cmap = 'Greys_r')\n",
    "    plt.axis('Off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V6j2-Q1Au1N9"
   },
   "outputs": [],
   "source": [
    "# MNIST 이미지 생성\n",
    "# 여기서는 10 * 10 = 100개의 MNIST 이미지 생성\n",
    "\n",
    "plot_latent_images(10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
